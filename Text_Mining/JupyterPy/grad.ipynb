{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "kkma = Kkma()\n",
    "\n",
    "#-*-coding:utf-8-*-\n",
    "# Mecab installation needed\n",
    "from konlpy.tag import Mecab\n",
    "mecab = Mecab(dicpath=\"C:/mecab/mecab-ko-dic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kkma.sentences('이것은 형태소 분석기 입니다 아버지가방에들어가신다')\n",
    "#mecab.morphs('이것은 형태소 분석기 입니다 아버지가방에들어가신다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kkma.nouns('이것은 형태소 분석기 입니다 아버지가방에들어가신다')\n",
    "#mecab.nouns('이것은 형태소 분석기 입니다 아버지가방에들어가신다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kkma.pos('이것은 형태소 분석기 입니다 아버지가방에들어가신다')\n",
    "#mecab.pos('이것은 형태소 분석기 입니다 아버지가방에들어가신다')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한글', '형태소', '분석기', '코모', '란', '테스트', '중', '이', 'ㅂ니다', '.', '^', '^', '오예', '!']\n",
      "['한글', '형태소', '분석기', '코모', '테스트', '중', '오예']\n",
      "[('한글', 'NNP'), ('형태소', 'NNP'), ('분석기', 'NNG'), ('코모', 'NNP'), ('란', 'JX'), ('테스트', 'NNP'), ('중', 'NNB'), ('^', 'SW'), ('^', 'SW'), ('오예', 'NNP'), ('!', 'SF')]\n",
      "\n",
      "\n",
      " ('한글', 'NNP')\n",
      "\n",
      "\n",
      " ('형태소', 'NNP')\n",
      "\n",
      "\n",
      " ('분석기', 'NNG')\n",
      "<class 'list'>\n",
      "\n",
      "\n",
      " 한글\n",
      "\n",
      "\n",
      " NNP\n"
     ]
    }
   ],
   "source": [
    "#사용자 사전 추가 링크\n",
    "#https://datascienceschool.net/view-notebook/4bfa8007982d4c7ba35d8b42cecd38c9/\n",
    "from konlpy.tag import Komoran\n",
    "komoran = Komoran()\n",
    "print(komoran.morphs(u'한글형태소분석기 코모란 테스트 중입니다. ^^ 오예 !'))\n",
    "print(komoran.nouns(u'한글형태소분석기 코모란 테스트 중입니다 ^^ 오예 !'))\n",
    "print(komoran.pos(u'한글형태소분석기 코모란 테스트 중 ^^ 오예 !'))\n",
    "\n",
    "arr_komoran = komoran.pos(u'한글형태소분석기 코모란 테스트 중 ^^ 오예 !')\n",
    "print(\"\\n\\n\", arr_komoran[0])\n",
    "print(\"\\n\\n\", arr_komoran[1])\n",
    "print(\"\\n\\n\", arr_komoran[2])\n",
    "\n",
    "print(type(arr_komoran))\n",
    "print(\"\\n\\n\", arr_komoran[0][0])\n",
    "print(\"\\n\\n\", arr_komoran[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 패키지와 라이브러리를 가져옴\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print ('버전: ', mpl.__version__)\n",
    "# print ('설치 위치: ', mpl.__file__)\n",
    "# print ('설정 위치: ', mpl.get_configdir())\n",
    "# print ('캐시 위치: ', mpl.get_cachedir())\n",
    "# print ('설정파일 위치: ', mpl.matplotlib_fname())\n",
    "\n",
    "font_list = fm.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "# ttf 폰트 전체갯수\n",
    "#print(\"\\n\\n시스템폰트 전체갯수:\", len(font_list)) \n",
    "\n",
    "# OSX 의 설치 된 폰트를 가져오는 함수\n",
    "#font_list_mac = fm.OSXInstalledFonts()\n",
    "#print(\"\\n설치된 폰트\", len(font_list_mac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"시스템폰트 리스트에서 상위 10개만 출력\")\n",
    "# for i in range(10) :\n",
    "#         print(i+1, \"\\t\", font_list[i], \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = [f.name for f in fm.fontManager.ttflist]\n",
    "\n",
    "# print(\"저장된 폰트중에서 10개만 출력\")\n",
    "# for i in range(10) :\n",
    "#         print(i+1, \"\\t\", f[i], \"\\t\")\n",
    "\n",
    "\n",
    "# [(f.name, f.fname) for f in fm.fontManager.ttflist\n",
    "#      if 'lower' in f.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#json파일 인코딩 문제 해결 코드\n",
    "\n",
    "def file_convert(filename):\n",
    "    convert_filename = 'result444.json'\n",
    "    bytes = min(32, os.path.getsize(filename))\n",
    "    raw = open(filename, 'rb').read(bytes)\n",
    "    \n",
    "    if raw.startswith(codecs.BOM_UTF8):\n",
    "        encoding = 'utf-8-sig'\n",
    "        \n",
    "    else:\n",
    "        result = chardet.detect(raw)\n",
    "        encoding = result['encoding']\n",
    "        \n",
    "    infile = io.open(filename, 'r', encoding=encoding)\n",
    "    data = infile.read()\n",
    "    infile.close()\n",
    "    \n",
    "    oo = open(convert_filename, 'w', encoding='UTF8')\n",
    "    oo.write(data)\n",
    "    oo.close()\n",
    "    \n",
    "    return convert_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CODE 1] 빈도수 체크 그래프 그리기\n",
    "def showGraph(wordInfo):\n",
    "    \n",
    "    font_location = \"c:/Windows/fonts/SangSangFlowerRoad.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "    matplotlib.rc('font', family=font_name)\n",
    "    \n",
    "    #font_location = \"c:/Windows/fonts/Josefin Sans.ttf\"\n",
    "    #font_name = font_manager.FontProperties(fname=font_location).get_name()\n",
    "    #matplotlib.rc('font', family=font_name)\n",
    "\n",
    "    plt.xlabel('주요 단어')\n",
    "    plt.ylabel('빈도수')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    Sorted_Dict_Values = sorted(wordInfo.values(), reverse=True)\n",
    "    Sorted_Dict_Keys = sorted(wordInfo, key=wordInfo.get, reverse=True)\n",
    "\n",
    "    plt.bar(range(len(wordInfo)), Sorted_Dict_Values, align='center')\n",
    "    plt.xticks(range(len(wordInfo)), list(Sorted_Dict_Keys), rotation='70')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[CODE 2] 새 창에 워드 클라우드 생성\n",
    "def saveWordCloud(wordInfo, filename):\n",
    "    \n",
    "    taglist = pytagcloud.make_tags(dict(wordInfo).items(), maxsize=80)\n",
    "    pytagcloud.create_tag_image(taglist, filename, size=(640, 480), fontname=\"korean\", rectangular=False)\n",
    "    webbrowser.open(filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# 한국어 파일 읽기\n",
    "#-*- encoding: utf8 -*-\n",
    "import sys\n",
    "from functools import update_wrapper\n",
    "from django.conf import settings\n",
    "from django.core.exceptions import ImproperlyConfigured\n",
    "from django.db.models.base import ModelBase\n",
    "from django.views.decorators.cache import never_cache\n",
    "from imp import reload\n",
    "reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')\n",
    "\n",
    "\n",
    "# 명사 추출 및 빈도 분석\n",
    "import json\n",
    "import re\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "from konlpy.utils import pprint\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib import font_manager, rc\n",
    "import matplotlib as mpl\n",
    "\n",
    "import pytagcloud\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "#from __future__ import print_function\n",
    "from lexrankr import LexRank\n",
    "from lexrank import STOPWORDS\n",
    "\n",
    "# 그래프를 노트북 안에 그리기 위해 설정\n",
    "%matplotlib inline\n",
    "\n",
    "# 그래프에서 마이너스 폰트 깨지는 문제에 대한 대처\n",
    "mpl.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "import numpy as np\n",
    "import io\n",
    "import chardet\n",
    "import os\n",
    "import codecs\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import copy\n",
    "\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "import MeCab\n",
    "\n",
    "from threading import Thread\n",
    "import jpype\n",
    "\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# 코드 6-3 케라스를 사용한 단어 수준의 원-핫 인코딩하기\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "#1차 정제\n",
    "import re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def study():\n",
    "    #여기서 파일의 경로는 실제 JSON 데이터가 저장된 경로이다\n",
    "    openFileName = 'C:/Users/DH\\Desktop/JupyterPy/rawdata/crawling/result1.json'\n",
    "    #openFileName = file_convert(\"result444.json\")\n",
    "    \n",
    "    cloudImagePath = openFileName + '.jpg'\n",
    "    rfile = open(openFileName, 'r', encoding='utf-8').read()\n",
    "    \n",
    "    jsonData = json.loads(rfile)\n",
    "    contents = ''\n",
    "    \n",
    "    \n",
    "    \n",
    "    #[CODE 3]\n",
    "    \n",
    "    for item in jsonData:\n",
    "        if 'contents' in item.keys():\n",
    "            print(\"\\n[content]\\n\", content, \"\\n\\n\")\n",
    "            #content = content + re.sub(r'[^\\w]', ' ', item['content']) + ' '\n",
    "            content = content + re.sub('\\n\\n', '.\\n', item['content']) + ' '\n",
    "        \n",
    "    #[CODE 4]\n",
    "    kkma = Kkma()\n",
    "    nouns = kkma.nouns(content)\n",
    "    count = Counter(nouns)\n",
    "    \n",
    "    #[CODE 6]\n",
    "    print(\"\\n[원문]\\n\", content, \"\\n\\n\")\n",
    "    lexrank = LexRank()\n",
    "    lexrank.summarize(content)\n",
    "\n",
    "    summaries = lexrank.probe()\n",
    "    print(\"\\n[요약문 전체]\",\"\\n\", summaries, \"\\n\")\n",
    "\n",
    "    for i, summary in enumerate(summaries):\n",
    "        print(\"\\n[요약문 일부\", str(i), \"]\\t\", summary, \"\\n\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #[CODE 5]\n",
    "    wordInfo = dict()\n",
    "    for tags, counts in count.most_common(50):\n",
    "        if (len(str(tags)) > 1):\n",
    "            wordInfo[tags] = counts\n",
    "            print (\"%s : %d\" % (tags, counts))\n",
    "            \n",
    "    plt.style.use('seaborn-pastel')      \n",
    "    \n",
    "    #showGraph(wordInfo) #그래프\n",
    "    #saveWordCloud(wordInfo, cloudImagePath) #워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쓰레드 예시 (나중에 쓸거같아서 일단 작성)\n",
    "def sentencing_with_multithread(lines):\n",
    "    nlines = len(liens)\n",
    "    results = []\n",
    "    t1 = Thread(target=sentencing, arg=(0, int(nlines/2), lines, results))\n",
    "    t2 = Thread(target=sentencing, arg=(int(nlines/2), nlines, lines, results))\n",
    "    t1.start()\n",
    "    t2.start()\n",
    "    t1.join()\n",
    "    t2.join()\n",
    "    jpype.detachThreadFromJVM()\n",
    "    return sum(sum(results, []), [])\n",
    "\n",
    "\n",
    "def sentencing(start, end, lines, results):\n",
    "    jpype.attachThreadToJVM()\n",
    "    sentences = [kkma.sentences(lines[i]) for i in range(start, end)]\n",
    "    results.append(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossFun(inputs, targets, hprev, cprev):\n",
    "    xs, hs, cs, is_, fs, os, gs, ys, ps= {}, {}, {}, {}, {}, {}, {}, {}, {}\n",
    "    hs[-1] = np.copy(hprev) # t=0일때 t-1 시점의 hidden state가 필요하므로\n",
    "    cs[-1] = np.copy(cprev)\n",
    "    loss = 0\n",
    "    #H = hidden_size\n",
    "    H = 100\n",
    "    \n",
    "    # forward pass\n",
    "    for t in range(len(inputs)):\n",
    "        xs[t] = np.zeros((len(inputs), 1))\n",
    "        xs[t][inputs[t]] = 1\n",
    "        tmp = np.dot(Wxh, xs[t]) + np.dot(Whh, hs[t - 1]) + bh  # hidden state\n",
    "        is_[t] = sigmoid(tmp[:H])\n",
    "        fs[t] = sigmoid(tmp[H:2 * H])\n",
    "        os[t] = sigmoid(tmp[2 * H: 3 * H])\n",
    "        gs[t] = np.tanh(tmp[3 * H:])\n",
    "        cs[t] = fs[t] * cs[t-1] + is_[t] * gs[t]\n",
    "        hs[t] = os[t] * np.tanh(cs[t])\n",
    "\n",
    "    # compute loss\n",
    "    for i in range(len(targets)):\n",
    "        idx = len(inputs) - len(targets) + i\n",
    "        ys[idx] = np.dot(Why, hs[idx]) + by  # unnormalized log probabilities for next chars\n",
    "        ps[idx] = np.exp(ys[idx]) / np.sum(np.exp(ys[idx]))  # probabilities for next chars\n",
    "        loss += -np.log(ps[idx][targets[i], 0])  # softmax (cross-entropy loss)\n",
    "\n",
    "    # backward pass: compute gradients going backwards\n",
    "    dWxh, dWhh, dWhy = np.zeros_like(Wxh), np.zeros_like(Whh), np.zeros_like(Why)\n",
    "    dbh, dby = np.zeros_like(bh), np.zeros_like(by)\n",
    "    dhnext, dcnext = np.zeros_like(hs[0]), np.zeros_like(cs[0])\n",
    "    n = 1\n",
    "    a = len(targets) - 1\n",
    "    for t in reversed(range(len(inputs))):\n",
    "        if n > len(targets):\n",
    "            continue\n",
    "        dy = np.copy(ps[t])\n",
    "        dy[targets[a]] -= 1  # backprop into y\n",
    "        dWhy += np.dot(dy, hs[t].T)\n",
    "        dby += dy\n",
    "        dh = np.dot(Why.T, dy) + dhnext  # backprop into h\n",
    "        dc = dcnext + (1 - np.tanh(cs[t]) * np.tanh(cs[t])) * dh * os[t]  # backprop through tanh nonlinearity\n",
    "        dcnext = dc * fs[t]\n",
    "        di = dc * gs[t]\n",
    "        df = dc * cs[t-1]\n",
    "        do = dh * np.tanh(cs[t])\n",
    "        dg = dc * is_[t]\n",
    "        ddi = (1 - is_[t]) * is_[t] * di\n",
    "        ddf = (1 - fs[t]) * fs[t] * df\n",
    "        ddo = (1 - os[t]) * os[t] * do\n",
    "        ddg = (1 - gs[t]^2) * dg\n",
    "        da = np.hstack((ddi.ravel(),ddf.ravel(),ddo.ravel(),ddg.ravel()))\n",
    "        dWxh += np.dot(da[:,np.newaxis],xs[t].T)\n",
    "        dWhh += np.dot(da[:,np.newaxis],hs[t-1].T)\n",
    "        dbh += da[:, np.newaxis]\n",
    "        dhnext = np.dot(Whh.T, da[:, np.newaxis])\n",
    "        n += 1\n",
    "        a -= 1\n",
    "    for dparam in [dWxh, dWhh, dWhy, dbh, dby]:\n",
    "        np.clip(dparam, -5, 5, out=dparam)  # clip to mitigate exploding gradients\n",
    "    return loss, dWxh, dWhh, dWhy, dbh, dby, hs[len(inputs) - 1], cs[len(inputs) - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_lexranked(contents):\n",
    "    \n",
    "    #데이터 요약\n",
    "#     if (contents):\n",
    "#         return \"\"\n",
    "    try:\n",
    "        contents = re.sub('\\n\\n', '.\\n', contents)\n",
    "        lexrank = LexRank()\n",
    "        lexrank.summarize(contents)\n",
    "        summaries = lexrank.probe()\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "#     for i, summary in enumerate(summaries):\n",
    "#         print(str(i), summary)\n",
    "    reform = summaries\n",
    "    \n",
    "    return reform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleansing(sentence):\n",
    "    # 1차 정제\n",
    "    #data = \"<p>\\n\\n\\n\\n\\n\\n \\n\\n \\n\\n\\n 2019년 7월 20일 새벽 6시 9분ㅋㅋㅋㅏㅏㅏㅏㅣㅣ.<br/></p>\"\n",
    "    soup = BeautifulSoup(sentence, \"html5lib\")\n",
    "    remove_tag = soup.get_text()\n",
    "    result_text = re.sub('[-_,=+#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》;\\n,[ㄱ-ㅎ,ㅏ-ㅣ]', ''\n",
    "                         , remove_tag)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleasing2(text):\n",
    "    pattern = '([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)' # E-mail주소제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '(http|ftp|https)://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+' # URL제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '([ㄱ-ㅎㅏ-ㅣ]+)' # 한글 자음, 모음 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '<[^>]*>'         # HTML 태그 제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    pattern = '[^\\w\\s]' # 특수기호제거\n",
    "    text = re.sub(pattern=pattern, repl='', string=text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_rawdata(path_to_json, json_files):\n",
    "    \n",
    "    # 빈 데이터프레임 정의\n",
    "    jsons_dataframe = pd.DataFrame(columns=['title', 'href', 'contents', 'reform'])\n",
    "    #jsons_dataframe.set_index('index_id', inplace=True)\n",
    "    #display(pd.DataFrame(jsons_dataframe))\n",
    "    \n",
    "    #인덱싱 및 데이터 끌어오기\n",
    "    for index, js in enumerate(json_files):  \n",
    "        with open(os.path.join(path_to_json, js), encoding='utf-8-sig') as json_file:\n",
    "            json_text = json.load(json_file)\n",
    "            #print(\"json_file: \", json_file)\n",
    "            #print(\"\\n--------------------------------------------\\n: \")\n",
    "            #print(json_text)\n",
    "            \n",
    "            \n",
    "            \n",
    "            # 태그별 데이터 저장\n",
    "            title = cleasing2(json_text['title'])\n",
    "            href = json_text['href']\n",
    "            contents = cleasing2(json_text['contents'])\n",
    "            #print(contents, \"컨텐츠츠\\n\")\n",
    "            #print(cleasing2(cleansing(contents)), \"컨텐츠츠츠츠\\n\\n\\n\\n\")\n",
    "            \n",
    "            reform = sent_lexranked(contents)\n",
    "            #reform = \"\"\n",
    "            \n",
    "                \n",
    "                \n",
    "\n",
    "            # 데이터프레임 저장\n",
    "            jsons_dataframe.loc[index] = [title, href, contents, reform]\n",
    "            \n",
    "            \n",
    "    #display(pd.DataFrame(jsons_dataframe))\n",
    "    return jsons_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 파일 찾기\n",
    "    path_to_json = u'C:/Users/DH/Desktop/wherewego-master/Source/resultdir/소량테스트'\n",
    "    #path_to_json = u'C:/Users/DH/Desktop/wherewego-master/Source/resultdir/서울 근교 힐링'\n",
    "    json_files = [pos_json for pos_json in os.listdir(path_to_json) if pos_json.endswith('.json')]\n",
    "    #print(json_files)  # for me this prints ['foo.json']\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #m = MeCab.Tagger()\n",
    "    #out = m.parse(\"미갑이 잘 설치되었는지 확인중입니다.\")\n",
    "    #print(out[5:])\n",
    "    #print(out)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # 데이터 정제 및 데이터프레임 생성\n",
    "    df = pull_rawdata(path_to_json, json_files)\n",
    "    \n",
    "    # 데이터프레임 출력\n",
    "    #pd.set_option('display.max_columns', None)  # or 1000\n",
    "    #pd.set_option('display.max_rows', None)  # or 1000\n",
    "    #pd.set_option('display.max_colwidth', -1)  # or 199\n",
    "    \n",
    "    print(df.iloc[:, [0,1,3]])\n",
    "    #print(df)\n",
    "    print(\"\\n\\n\\n끝\\n\\n\\n\")\n",
    "    \n",
    "#     with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#         print(df[:][:1])\n",
    "        \n",
    "#     from IPython.core.display import HTML\n",
    "#     display(HTML(df[:,:].to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n",
      "C:\\Users\\DH\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py:16: UserWarning: \"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
      "  warn('\"Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         title  \\\n",
      "0                            서울여행지 도심 속 정원 석파정   \n",
      "1                         서울여행 추천코스  종로 중구 을지로   \n",
      "2             서울 여행 북악스카이웨이 팔각정 드라이브 코스 돌고 왔어요   \n",
      "3             서울여행의 꽃 광장시장에서 먹방투어 대잔치  거리의 셰프들   \n",
      "4                              딸과 단둘이서 떠난 서울여행   \n",
      "5                          서울여행 세번째로 서울숲으로 완전짱   \n",
      "6            서울여행 배롱나무가 아름다운 덕수궁 현충원 찍고 동작대교노을   \n",
      "7  2박3일 서울여행  그랜드하얏트서울 서울일러스트레이션페어 2019 홍대 나들이   \n",
      "8                   0 서울여행_이틀동안 다섯 전시 프로젝트의 시작   \n",
      "9                서울여행  가볼만한 곳 북한산 자락의 은평구 한옥마을   \n",
      "\n",
      "                                                href  \\\n",
      "0  https://blog.naver.com/PostView.nhn?blogId=suh...   \n",
      "1  https://blog.naver.com/PostView.nhn?blogId=rea...   \n",
      "2  https://blog.naver.com/PostView.nhn?blogId=jej...   \n",
      "3  https://blog.naver.com/PostView.nhn?blogId=yuk...   \n",
      "4  https://blog.naver.com/PostView.nhn?blogId=rud...   \n",
      "5  https://blog.naver.com/PostView.nhn?blogId=sav...   \n",
      "6  https://blog.naver.com/PostView.nhn?blogId=jun...   \n",
      "7  https://blog.naver.com/PostView.nhn?blogId=ora...   \n",
      "8  https://blog.naver.com/PostView.nhn?blogId=dba...   \n",
      "9  https://blog.naver.com/PostView.nhn?blogId=hjk...   \n",
      "\n",
      "                                              reform  \n",
      "0  [흥선대원군이 이곳을 좋아한 이유는 와 보니 수긍이 가더라고요 푸르른 나무 사이에서...  \n",
      "1  [서울 여행은 대부분의 여행지를 걸어서 이동하기 때문에 되도록 동선이 짧고 연결된 ...  \n",
      "2  [오늘 이른 새벽 6시 25분 버스를 타서 서울로 올라오기 위해 밤을 새우기도 했고...  \n",
      "3  [육회비빔이랑 파전 먹을까 하다가 여기서 왠 파전이냐 싶어서  그냥 일반 육회비빔밥...  \n",
      "4  [아빠랑 아들의 점심 도시락을 준비하면서 저랑 딸이랑 기차에서 먹을 김밥도 함께 준...  \n",
      "5  [여기가 또 포토존이라고 합니다사진이 정말 잘나오는 자리에요멀리서 찍으면 더 잘나와...  \n",
      "6  [서울여행 배롱나무가 아름다운 곳을 찾아서 여행을 하시려고 해도 현충원배롱나무 덕수...  \n",
      "7  [흐린 야경도 넘나 아쉬웠다 오크우드 가려다가 뷰 때문에 그랜드 하얏트 서울 예약했...  \n",
      "8  [수업중에 당첨 문자를 받았고 옆 자리 앉은 친구에게 곧바로 자랑하다가 기왕 갈거면...  \n",
      "9  [한옥마을 뒤로 보이는 북한산이 모든 풍경이 상당히 잘 어울렸다사실 한옥마을에서 뭔...  \n",
      "\n",
      "\n",
      "\n",
      "끝\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#임포트말고 직접실행\n",
    "if __name__ == \"__main__\":\n",
    "    #study()\n",
    "    #print(\"===============================================================================================\")\n",
    "    \n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
